In mathematics, statistics, finance, and computer science, particularly in machine learning and inverse problems, regularization is a process that converts the answer to a problem to a simpler one. It is often used in solving ill-posed problems or to prevent overfitting.
Although regularization procedures can be divided in many ways, the following delineation is particularly helpful:

Explicit regularization is regularization whenever one explicitly adds a term to the optimization problem.  These terms could be priors, penalties, or constraints. Explicit regularization is commonly employed with ill-posed optimization problems. The regularization term, or penalty, imposes a cost on the optimization function to make the optimal solution unique.
Implicit regularization is all other forms of regularization.  This includes, for example, early stopping, using a robust loss function, and discarding outliers. Implicit regularization is essentially ubiquitous in modern machine learning approaches, including stochastic gradient descent for training deep neural networks, and ensemble methods (such as random forests and gradient boosted trees).
In explicit regularization, independent of the problem or model, there is always a data term, that corresponds to a likelihood of the measurement, and a regularization term that corresponds to a prior. By combining both using Bayesian statistics, one can compute a posterior, that includes both information sources and therefore stabilizes the estimation process. By trading off both objectives, one chooses to be more aligned to the data or to enforce regularization (to prevent overfitting). There is a whole research branch dealing with all possible regularizations. In practice, one usually tries a specific regularization and then figures out the probability density that corresponds to that regularization to justify the choice. It can also be physically motivated by common sense or intuition.
In machine learning, the data term corresponds to the training data and the regularization is either the choice of the model or modifications to the algorithm. It is always intended to reduce the generalization error, i.e. the error score with the trained model on the evaluation set (testing data) and not the training data.
One of the earliest uses of regularization is Tikhonov regularization (ridge regression), related to the method of least squares.


## Regularization in machine learning
In machine learning, a key challenge is enabling models to accurately predict outcomes on unseen data, not just on familiar training data. Regularization is crucial for addressing overfitting—where a model memorizes training data details but cannot generalize to new data. The goal of regularization is to encourage models to learn the broader patterns within the data rather than memorizing it. Techniques like early stopping, L1 and L2 regularization, and dropout are designed to prevent overfitting and underfitting, thereby enhancing the model's ability to adapt to and perform well with new data, thus improving model generalization.

## Classification
Empirical learning of classifiers (from a finite data set) is always an underdetermined problem, because it attempts to infer a function of any 
  
    
      
        x
      
    
    {\displaystyle x}
  
 given only examples 
  
    
      
        
          x
          
            1
          
        
        ,
        
          x
          
            2
          
        
        ,
        …
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},x_{2},\dots ,x_{n}}
  
.
A regularization term (or regularizer) 
  
    
      
        R
        (
        f
        )
      
    
    {\displaystyle R(f)}
  
 is added to a loss function:

  
    
      
        
          min
          
            f
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        V
        (
        f
        (
        
          x
          
            i
          
        
        )
        ,
        
          y
          
            i
          
        
        )
        +
        λ
        R
        (
        f
        )
      
    
    {\displaystyle \min _{f}\sum _{i=1}^{n}V(f(x_{i}),y_{i})+\lambda R(f)}
  

where 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is an underlying loss function that describes the cost of predicting 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  
 when the label is 
  
    
      
        y
      
    
    {\displaystyle y}
  
, such as the square loss or hinge loss; and 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
  
 is a parameter which controls the importance of the regularization term. 
  
    
      
        R
        (
        f
        )
      
    
    {\displaystyle R(f)}
  
 is typically chosen to impose a penalty on the complexity of 
  
    
      
        f
      
    
    {\displaystyle f}
  
. Concrete notions of complexity used include restrictions for smoothness and bounds on the vector space norm.
A theoretical justification for regularization is that it attempts to impose Occam's razor on the solution (as depicted in the figure above, where the green function, the simpler one, may be preferred). From a Bayesian point of view, many regularization techniques correspond to imposing certain prior distributions on model parameters.
Regularization can serve multiple purposes, including learning simpler models, inducing models to be sparse and introducing group structure into the learning problem.
The same idea arose in many fields of science. A simple form of regularization applied to integral equations (Tikhonov regularization)  is essentially a trade-off between fitting the data and reducing a norm of the solution. More recently, non-linear regularization methods, including total variation regularization, have become popular.

## Tikhonov regularization (ridge regression)
These techniques are named for Andrey Nikolayevich Tikhonov, who applied regularization to integral equations and made important contributions in many other areas.
When learning a linear function 
  
    
      
        f
      
    
    {\displaystyle f}
  
, characterized by an unknown vector 
  
    
      
        w
      
    
    {\displaystyle w}
  
 such that 
  
    
      
        f
        (
        x
        )
        =
        w
        ⋅
        x
      
    
    {\displaystyle f(x)=w\cdot x}
  
, one can add the 
  
    
      
        
          L
          
            2
          
        
      
    
    {\displaystyle L_{2}}
  
-norm of the vector 
  
    
      
        w
      
    
    {\displaystyle w}
  
 to the loss expression in order to prefer solutions with smaller norms. Tikhonov regularization is one of the most common forms. It is also known as ridge regression. It is expressed as:

  
    
      
        
          min
          
            w
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        V
        (
        
          
            
              
                x
                ^
              
            
          
          
            i
          
        
        ⋅
        w
        ,
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
        )
        +
        λ
        
          
            ‖
            w
            ‖
          
          
            2
          
          
            2
          
        
        ,
      
    
    {\displaystyle \min _{w}\sum _{i=1}^{n}V({\hat {x}}_{i}\cdot w,{\hat {y}}_{i})+\lambda \left\|w\right\|_{2}^{2},}
  

where 
  
    
      
        (
        
          
            
              
                x
                ^
              
            
          
          
            i
          
        
        ,
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
        )
        ,
        
        1
        ≤
        i
        ≤
        n
        ,
      
    
    {\displaystyle ({\hat {x}}_{i},{\hat {y}}_{i}),\,1\leq i\leq n,}
  
 would represent samples used for training.
In the case of a general function, the norm of the function in its reproducing kernel Hilbert space is:

  
    
      
        
          min
          
            f
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        V
        (
        f
        (
        
          
            
              
                x
                ^
              
            
          
          
            i
          
        
        )
        ,
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
        )
        +
        λ
        
          
            ‖
            f
            ‖
          
          
            
              H
            
          
          
            2
          
        
      
    
    {\displaystyle \min _{f}\sum _{i=1}^{n}V(f({\hat {x}}_{i}),{\hat {y}}_{i})+\lambda \left\|f\right\|_{\mathcal {H}}^{2}}
  

As the 
  
    
      
        
          L
          
            2
          
        
      
    
    {\displaystyle L_{2}}
  
 norm is differentiable, learning can be advanced by gradient descent.

## Early stopping
Early stopping can be viewed as regularization in time. Intuitively, a training procedure such as gradient descent tends to learn more and more complex functions with increasing iterations. By regularizing for time, model complexity can be controlled, improving generalization.
Early stopping is implemented using one data set for training, one statistically independent data set for validation and another for testing. The model is trained until performance on the validation set no longer improves and then applied to the test set.

## Regularizers for sparsity
Assume that a dictionary 
  
    
      
        
          ϕ
          
            j
          
        
      
    
    {\displaystyle \phi _{j}}
  
 with dimension 
  
    
      
        p
      
    
    {\displaystyle p}
  
 is given such that a function in the function space can be expressed as:

  
    
      
        f
        (
        x
        )
        =
        
          ∑
          
            j
            =
            1
          
          
            p
          
        
        
          ϕ
          
            j
          
        
        (
        x
        )
        
          w
          
            j
          
        
      
    
    {\displaystyle f(x)=\sum _{j=1}^{p}\phi _{j}(x)w_{j}}
  

Enforcing a sparsity constraint on 
  
    
      
        w
      
    
    {\displaystyle w}
  
 can lead to simpler and more interpretable models. This is useful in many real-life applications such as computational biology. An example is developing a simple predictive test for a disease in order to minimize the cost of performing medical tests while maximizing predictive power.
A sensible sparsity constraint is the 
  
    
      
        
          L
          
            0
          
        
      
    
    {\displaystyle L_{0}}
  
 norm 
  
    
      
        ‖
        w
        
          ‖
          
            0
          
        
      
    
    {\displaystyle \|w\|_{0}}
  
, defined as the number of non-zero elements in 
  
    
      
        w
      
    
    {\displaystyle w}
  
. Solving a 
  
    
      
        
          L
          
            0
          
        
      
    
    {\displaystyle L_{0}}
  
 regularized learning problem, however, has been demonstrated to be NP-hard.
The 
  
    
      
        
          L
          
            1
          
        
      
    
    {\displaystyle L_{1}}
  
 norm (see also Norms) can be used to approximate the optimal 
  
    
      
        
          L
          
            0
          
        
      
    
    {\displaystyle L_{0}}
  
 norm via convex relaxation. It can be shown that the 
  
    
      
        
          L
          
            1
          
        
      
    
    {\displaystyle L_{1}}
  
 norm induces sparsity. In the case of least squares, this problem is known as LASSO in statistics and basis pursuit in signal processing.

  
    
      
        
          min
          
            w
            ∈
            
              
                R
              
              
                p
              
            
          
        
        
          
            1
            n
          
        
        
          
            ‖
            
              
                
                  
                    X
                    ^
                  
                
              
              w
              −
              
                
                  
                    Y
                    ^
                  
                
              
            
            ‖
          
          
            2
          
        
        +
        λ
        
          
            ‖
            w
            ‖
          
          
            1
          
        
      
    
    {\displaystyle \min _{w\in \mathbb {R} ^{p}}{\frac {1}{n}}\left\|{\hat {X}}w-{\hat {Y}}\right\|^{2}+\lambda \left\|w\right\|_{1}}
  

  
    
      
        
          L
          
            1
          
        
      
    
    {\displaystyle L_{1}}
  
 regularization can occasionally produce non-unique solutions. A simple example is provided in the figure when the space of possible solutions lies on a 45 degree line. This can be problematic for certain applications, and is overcome by combining 
  
    
      
        
          L
          
            1
          
        
      
    
    {\displaystyle L_{1}}
  
 with 
  
    
      
        
          L
          
            2
          
        
      
    
    {\displaystyle L_{2}}
  
 regularization in elastic net regularization, which takes the following form:

  
    
      
        
          min
          
            w
            ∈
            
              
                R
              
              
                p
              
            
          
        
        
          
            1
            n
          
        
        
          
            ‖
            
              
                
                  
                    X
                    ^
                  
                
              
              w
              −
              
                
                  
                    Y
                    ^
                  
                
              
            
            ‖
          
          
            2
          
        
        +
        λ
        
          (
          
            α
            
              
                ‖
                w
                ‖
              
              
                1
              
            
            +
            (
            1
            −
            α
            )
            
              
                ‖
                w
                ‖
              
              
                2
              
              
                2
              
            
          
          )
        
        ,
        α
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle \min _{w\in \mathbb {R} ^{p}}{\frac {1}{n}}\left\|{\hat {X}}w-{\hat {Y}}\right\|^{2}+\lambda \left(\alpha \left\|w\right\|_{1}+(1-\alpha )\left\|w\right\|_{2}^{2}\right),\alpha \in [0,1]}
  

Elastic net regularization tends to have a grouping effect, where correlated input features are assigned equal weights.
Elastic net regularization is commonly used in practice and is implemented in many machine learning libraries.

## Regularizers for semi-supervised learning
When labels are more expensive to gather than input examples, semi-supervised learning can be useful. Regularizers have been designed to guide learning algorithms to learn models that respect the structure of unsupervised training samples. If a symmetric weight matrix 
  
    
      
        W
      
    
    {\displaystyle W}
  
 is given, a regularizer can be defined:

  
    
      
        R
        (
        f
        )
        =
        
          ∑
          
            i
            ,
            j
          
        
        
          w
          
            i
            j
          
        
        
          
            (
            
              f
              (
              
                x
                
                  i
                
              
              )
              −
              f
              (
              
                x
                
                  j
                
              
              )
            
            )
          
          
            2
          
        
      
    
    {\displaystyle R(f)=\sum _{i,j}w_{ij}\left(f(x_{i})-f(x_{j})\right)^{2}}
  

If 
  
    
      
        
          W
          
            i
            j
          
        
      
    
    {\displaystyle W_{ij}}
  
 encodes the result of some distance metric for points 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  
 and 
  
    
      
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{j}}
  
, it is desirable that 
  
    
      
        f
        (
        
          x
          
            i
          
        
        )
        ≈
        f
        (
        
          x
          
            j
          
        
        )
      
    
    {\displaystyle f(x_{i})\approx f(x_{j})}
  
. This regularizer captures this intuition, and is equivalent to:

  
    
      
        R
        (
        f
        )
        =
        
          
            
              
                f
                ¯
              
            
          
          
            
              T
            
          
        
        L
        
          
            
              f
              ¯
            
          
        
      
    
    {\displaystyle R(f)={\bar {f}}^{\mathsf {T}}L{\bar {f}}}
  
 where 
  
    
      
        L
        =
        D
        −
        W
      
    
    {\displaystyle L=D-W}
  
 is the Laplacian matrix of the graph induced by 
  
    
      
        W
      
    
    {\displaystyle W}
  
.
The optimization problem 
  
    
      
        
          min
          
            f
            ∈
            
              
                R
              
              
                m
              
            
          
        
        R
        (
        f
        )
        ,
        m
        =
        u
        +
        l
      
    
    {\displaystyle \min _{f\in \mathbb {R} ^{m}}R(f),m=u+l}
  
 can be solved analytically if the constraint 
  
    
      
        f
        (
        
          x
          
            i
          
        
        )
        =
        
          y
          
            i
          
        
      
    
    {\displaystyle f(x_{i})=y_{i}}
  
 is applied for all supervised samples. The labeled part of the vector 
  
    
      
        f
      
    
    {\displaystyle f}
  
 is therefore obvious. The unlabeled part of 
  
    
      
        f
      
    
    {\displaystyle f}
  
 is solved for by:

  
    
      
        
          min
          
            
              f
              
                u
              
            
            ∈
            
              
                R
              
              
                u
              
            
          
        
        
          f
          
            
              T
            
          
        
        L
        f
        =
        
          min
          
            
              f
              
                u
              
            
            ∈
            
              
                R
              
              
                u
              
            
          
        
        
          {
          
            
              f
              
                u
              
              
                
                  T
                
              
            
            
              L
              
                u
                u
              
            
            
              f
              
                u
              
            
            +
            
              f
              
                l
              
              
                
                  T
                
              
            
            
              L
              
                l
                u
              
            
            
              f
              
                u
              
            
            +
            
              f
              
                u
              
              
                
                  T
                
              
            
            
              L
              
                u
                l
              
            
            
              f
              
                l
              
            
          
          }
        
      
    
    {\displaystyle \min _{f_{u}\in \mathbb {R} ^{u}}f^{\mathsf {T}}Lf=\min _{f_{u}\in \mathbb {R} ^{u}}\left\{f_{u}^{\mathsf {T}}L_{uu}f_{u}+f_{l}^{\mathsf {T}}L_{lu}f_{u}+f_{u}^{\mathsf {T}}L_{ul}f_{l}\right\}}
  

  
    
      
        
          ∇
          
            
              f
              
                u
              
            
          
        
        =
        2
        
          L
          
            u
            u
          
        
        
          f
          
            u
          
        
        +
        2
        
          L
          
            u
            l
          
        
        Y
      
    
    {\displaystyle \nabla _{f_{u}}=2L_{uu}f_{u}+2L_{ul}Y}
  

  
    
      
        
          f
          
            u
          
        
        =
        
          L
          
            u
            u
          
          
            †
          
        
        
          (
          
            
              L
              
                u
                l
              
            
            Y
          
          )
        
      
    
    {\displaystyle f_{u}=L_{uu}^{\dagger }\left(L_{ul}Y\right)}
  

The pseudo-inverse can be taken because 
  
    
      
        
          L
          
            u
            l
          
        
      
    
    {\displaystyle L_{ul}}
  
 has the same range as 
  
    
      
        
          L
          
            u
            u
          
        
      
    
    {\displaystyle L_{uu}}
  
.

## Regularizers for multitask learning
In the case of multitask learning, 
  
    
      
        T
      
    
    {\displaystyle T}
  
 problems are considered simultaneously, each related in some way. The goal is to learn 
  
    
      
        T
      
    
    {\displaystyle T}
  
 functions, ideally borrowing strength from the relatedness of tasks, that have predictive power. This is equivalent to learning the matrix 
  
    
      
        W
        :
        T
        ×
        D
      
    
    {\displaystyle W:T\times D}
  
 .

## Other uses of regularization in statistics and machine learning
Bayesian learning methods make use of a prior probability that (usually) gives lower probability to more complex models. Well-known model selection techniques include the Akaike information criterion (AIC), minimum description length (MDL), and the Bayesian information criterion (BIC). Alternative methods of controlling overfitting not involving regularization include cross-validation.
Examples of applications of different methods of regularization to the linear model are:

## See also
Bayesian interpretation of regularization
Bias–variance tradeoff
Matrix regularization
Regularization by spectral filtering
Regularized least squares
Lagrange multiplier
Variance reduction

## Notes


## References
Neumaier, A. (1998). "Solving ill-conditioned and singular linear systems: A tutorial on regularization" (PDF). SIAM Review. 40 (3): 636–666. Bibcode:1998SIAMR..40..636N. doi:10.1137/S0036144597321909. Archived from the original (PDF) on 2007-06-30.
Kukačka, Jan; Golkov, Vladimir; Cremers, Daniel (2017). "Regularization for Deep Learning: A Taxonomy". arXiv:1710.10686 [cs.LG].